{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjfuentes/IAGenerativa/blob/main/Microsoft/AI_foundry_MAF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install -q \"mcp>=1.23.1\" agent-framework azure-ai-projects python-dotenv\n",
        "%pip install -q --pre azure-ai-projects>=2.0.0b1 azure-identity"
      ],
      "metadata": {
        "id": "UJXbVqDdz1xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1) IMPORTS Y CONFIGURACIÓN INICIAL\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Lectura de credenciales desde un archivo de texto\n",
        "# El archivo debe tener EXACTAMENTE 3 líneas en este orden:\n",
        "#   1) AZURE_CLIENT_ID\n",
        "#   2) AZURE_CLIENT_SECRET\n",
        "#   3) AZURE_TENANT_ID\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "with open(\"/content/aifoundrymaf.txt\", \"r\") as archivo:\n",
        "  lineas = archivo.read().splitlines()\n",
        "\n",
        "# Desempaquetado: asigna cada línea a una variable\n",
        "azure_client_id, azure_client_secret, azure_tenant_id = lineas\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Variables de entorno para autenticación con Azure\n",
        "# DefaultAzureCredential() leerá estas variables\n",
        "# ------------------------------------------------------------\n",
        "os.environ[\"AZURE_CLIENT_ID\"]=azure_client_id\n",
        "os.environ[\"AZURE_CLIENT_SECRET\"]=azure_client_secret #certificado y secretos: clave-foundry-colab\n",
        "os.environ[\"AZURE_TENANT_ID\"]=azure_tenant_id\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Endpoint del proyecto en Azure AI Foundry\n",
        "# IMPORTANTE: Debe ser el endpoint del proyecto correcto\n",
        "# ------------------------------------------------------------\n",
        "###os.environ[\"AZURE_AI_FOUNDRY_PROJECT_ENDPOINT\"] =\"https://mac-foundry-agent.services.ai.azure.com/api/projects/proj-agent\"\n",
        "os.environ[\"AZURE_AI_FOUNDRY_PROJECT_ENDPOINT\"] =\"https://modelo-foundry-colab.services.ai.azure.com/api/projects/proj-modelo-foundry-colab\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Parámetros de configuración del agente\n",
        "# agent_name: nombre lógico del agente (reutilizable)\n",
        "# model_id: modelo que usará el agente\n",
        "# embedding_id: se usará cuando agregues RAG / embeddings\n",
        "# ------------------------------------------------------------\n",
        "agent_name = \"CODX-agentSolution-qa01\"\n",
        "model_id = \"gpt-4.1-mini\"\n",
        "embedding_id=\"text-embedding-3-small\""
      ],
      "metadata": {
        "id": "l5ilrP6f6zWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8vob1QMyQoi",
        "outputId": "cd87ecf6-6cdc-4524-9804-bc9b949ffbd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent created (id: CODX-agentSolution-qa01:2, name: CODX-agentSolution-qa01, version: 2)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 2) CREACIÓN DEL AGENTE (MAF + AI FOUNDY)\n",
        "# ============================================================\n",
        "\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "from azure.ai.projects.models import PromptAgentDefinition\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Crear el cliente del proyecto de AI Foundry\n",
        "# credential=DefaultAzureCredential() usará las variables de entorno\n",
        "# ------------------------------------------------------------\n",
        "project_client = AIProjectClient(\n",
        "    endpoint=os.environ[\"AZURE_AI_FOUNDRY_PROJECT_ENDPOINT\"],\n",
        "    credential=DefaultAzureCredential(),\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Crear (o versionar) un agente tipo Prompt Agent\n",
        "# - create_version crea una nueva versión del agente\n",
        "# - instructions actúan como \"system prompt\" persistente\n",
        "# ------------------------------------------------------------\n",
        "agent = project_client.agents.create_version(\n",
        "    agent_name=agent_name,\n",
        "    definition=PromptAgentDefinition(\n",
        "        model=model_id,\n",
        "        instructions=\"\"\" Eres un asistente amable y especializado en matemáticas\n",
        "         no debes responder preguntas de otro tema e indicar que no estas habilitado para dar información de un tema distinto, se breve\"\"\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Mostrar datos relevantes del agente creado/versionado\n",
        "print(f\"Agene creado (id: {agent.id}, nombre: {agent.name}, version: {agent.version})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3) USO DEL AGENTE – MODO BASE / PRUEBA SIMPLE (SIN MEMORIA)\n",
        "# ============================================================\n",
        "# OBJETIVO:\n",
        "# Probar que un agente (creado por IU o por código) responde\n",
        "# correctamente a UNA sola pregunta.\n",
        "#\n",
        "# IMPORTANTE:\n",
        "# - No se reutiliza el contexto para múltiples turnos.\n",
        "# - Aunque se cree una conversación, se usa solo una vez.\n",
        "# - Conceptualmente, esto es equivalente a \"stateless usage\".\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Conexión al proyecto de Azure AI Foundry\n",
        "# Se reutiliza el endpoint configurado previamente\n",
        "# ------------------------------------------------------------\n",
        "project_client = AIProjectClient(\n",
        "    endpoint=os.environ[\"AZURE_AI_FOUNDRY_PROJECT_ENDPOINT\"],\n",
        "    credential=DefaultAzureCredential(),\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Cliente OpenAI-compatible para usar Responses y Conversations\n",
        "# ------------------------------------------------------------\n",
        "openai_client = project_client.get_openai_client()\n",
        "\n",
        "# Paso opcional: Creamos una conversacion para usar el agente\n",
        "conversation = openai_client.conversations.create()\n",
        "print(f\"ID de conversacion: {conversation.id}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Envío de UNA pregunta al agente\n",
        "# - Se usa un agente ya existente (creado por UI o código)\n",
        "# - agent_reference evita recrear el agente\n",
        "# - Este uso es SINGLE-TURN (sin continuidad)\n",
        "# ------------------------------------------------------------\n",
        "response = openai_client.responses.create(\n",
        "    conversation=conversation.id, #Optional conversation context for multi-turn\n",
        "    extra_body={\"agent\": {\"name\": agent_name, \"type\": \"agent_reference\"}},\n",
        "    input=\"¿Cuál es el tamaño de Francia en millas cuadradas?\",\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Mostrar la respuesta del agente\n",
        "# ------------------------------------------------------------\n",
        "print(f\"Respuesta: {response.output_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXv5z58n1ck4",
        "outputId": "6dab70f3-edda-4ca2-a4fd-c50a60f47cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID de conversacion: conv_8e15a10ab49d09bd003MlzMudxzteuYHpgcOrABXeCUO23s7fd\n",
            "Respuesta: No estoy habilitado para proporcionar información de temas distintos a matemáticas. ¿Quieres ayuda con algún problema o concepto matemático?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 4) USO DEL AGENTE CON CONVERSACIÓN (MEMORIA DE SESIÓN)\n",
        "# ============================================================\n",
        "# NOTA: La \"memoria\" aquí es la conversación:\n",
        "# Si usas el mismo conversation.id en múltiples turns,\n",
        "# el agente podrá recordar lo que se habló antes (multi-turn).\n",
        "# ============================================================\n",
        "import os\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Conexión al proyecto de Azure AI Foundry\n",
        "# Se reutiliza el endpoint configurado previamente\n",
        "# ------------------------------------------------------------\n",
        "project_client = AIProjectClient(\n",
        "    endpoint=os.environ[\"AZURE_AI_FOUNDRY_PROJECT_ENDPOINT\"],\n",
        "    credential=DefaultAzureCredential(),\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Obtener el cliente OpenAI-compatible (Responses + Conversations)\n",
        "# ------------------------------------------------------------\n",
        "openai_client = project_client.get_openai_client()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Crear UNA conversación.\n",
        "# IMPORTANTÍSIMO: Reutiliza conversation.id para mantener memoria.\n",
        "# Si creas otra conversación, es como empezar de cero.\n",
        "# ------------------------------------------------------------\n",
        "conversation = openai_client.conversations.create()\n",
        "print(f\"ID de conversación: {conversation.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIqwH2rj6VCO",
        "outputId": "87f77b5f-ef0a-47a3-8f2f-38976fbed337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID de conversación: conv_6a0d1682277aac1d00BEtdsu4UU0e1UlgqExQEYOeIS8waZ8p3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# TURNO 1 (pregunta inicial)\n",
        "# -------------------------\n",
        "resp1 = openai_client.responses.create(\n",
        "    conversation=conversation.id,  # <-- MISMA conversación = guarda contexto\n",
        "    extra_body={\"agent\": {\"name\": agent_name, \"type\": \"agent_reference\"}},\n",
        "    input=\"¿Cuánto es 3 + 2?\"\n",
        ")\n",
        "\n",
        "print(\"Turno 1:\", resp1.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zksP1MrCM2Z",
        "outputId": "3b83f33e-66ae-45f0-d458-593066e7ca3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turno 1: 3 + 2 es igual a 5. ¿Necesitas ayuda con alguna otra operación?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# TURNO 2 (referencia al resultado previo)\n",
        "# -------------------------\n",
        "resp2 = openai_client.responses.create(\n",
        "    conversation=conversation.id,  # <-- misma conversación = recuerda el turno 1\n",
        "    extra_body={\"agent\": {\"name\": agent_name, \"type\": \"agent_reference\"}},\n",
        "    input=\"Multiplica el resultado por 6.\"\n",
        ")\n",
        "\n",
        "print(\"Turno 2:\", resp2.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tByhCJnyCpEr",
        "outputId": "0695d65c-584b-4838-9dd5-dbade450f12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turno 2: El resultado de 5 multiplicado por 6 es 30. ¿Quieres que te ayude con otro cálculo?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SaUBWAKCtBX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}